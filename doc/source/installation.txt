************
Installation
************

Getting the code
================

The code is available on a git repository, hosted on github: `https://github.com/ita-solar/rh <https://github.com/ita-solar/rh>`_. If you don't have `git <http://git-scm.com/>`_ installed and just want to get started, the easiest way is to download a zip file with the latest revision: `https://github.com/ita-solar/rh/archive/master.zip <https://github.com/ita-solar/rh/archive/master.zip>`_. If you have git installed and would like to be up-to-date with the repository, you can do a git clone::

    git clone https://github.com/ita-solar/rh.git

or using SSH (only for contributors)::

    git clone git@github.com:ita-solar/rh.git

Whether you unpack the zip file or do one of the above it will create a directory called ``rh`` in your current path. This directory will have the following subdirectories:

================ ============================================================
Directory        Contents
================ ============================================================
rh               Main RH source
rh/Atmos         Used to keep atmosphere files
rh/Atoms_example Used to keep atom files, line and wavelength lists (example)
rh/idl           Old RH IDL routines, not used
rh/Molecules     Used to keep molecule files
rh/python        Utility Python programs
rh/rh15d_mpi     Source files for RH 1.5D
rh/rhf1d         Source files for 1D geometry, **deprecated, do not use**
rh/rhsc2d        Source files for 2D geometry, **deprecated, do not use**
rh/rhsc3d        Source files for 3D geometry, **deprecated, do not use**
rh/rhsphere      Source files for spherical geometry, **deprecated, do not use**
rh/tools         Associate C programs for RH, not tested.
================ ============================================================

.. warning::
   The source code directories for different geometries (rhf1d, rhsc2d, rhsc3d, rhsphere) are still in the code tree, but they are deprecated and will be removed soon. With the latest changes related to rh15d, they are not guaranteed to work or even run. Do not use.


Dependencies
============

HDF5
----

RH 1.5D makes use of the `HDF5 <http://www.hdfgroup.org/HDF5/>`_ library to read the atmosphere files and write the output.  It is not possible to run the code without this library. RH 1.5D requires HDF5 version 1.8.1 or newer (versions from branch 1.10.x do not currently work).

.. note::
   RH 1.5D previously made use of the netCDF4 library for its output (which in turn also required HDF5). The latest changes mean RH 1.5D needs only HDF5. Because netCDF4 files are also HDF5 files, the output is still readable in the same way as before and input files in netCDF version 4 format can still be read in the same way by RH 1.5D. If you used input atmospheres in netCDF version 3 format, then these will have to be converted to HDF5. It is recommended that new atmosphere files be created in HDF5 only.

Because HDF5 is commonly used in high-performance computing, many supercomputers already have them available. In Fram, they can be loaded as (also loading the intel compilers)::

    module load HDF5/1.8.18-intel-2017a intel/2017a

in Pleiades::

    module load hdf5/1.8.7/gcc/mpt

in Hexagon::

    module load cray-hdf5-parallel

and at ITA's Linux system::

    module load hdf5/Intel/1.8.19

MPI
---

RH 1.5D is parallelised via MPI, therefore an MPI library is necessary even if running with only one CPU. These are readily available in supercomputers and clusters, but not always in individual workstations. In such cases, users will have to manually install both MPI and HDF5 libraries (HDF5 should be compiled with the MPI library so that the parallel I/O module works). 

If using Linux or MacOS, the easiest way to install both MPI and HDF5 with parallel support is via the `Anaconda <https://www.anaconda.com/download/#macos>`_ Python distribution. Once you install Anaconda (version 3.6 or above), you can install the ``hdf5-parallel`` package, which installs both MPI and HDF5 and has been tested with RH 1.5D::

    conda install -c spectraldns hdf5-parallel


.. warning::
   If you obtain pre-compiled binaries or packages for HDF5, you need to make sure they have parallel support enabled. Most available packages **do not have parallel support**. This includes typical packages from Linux distributions and the ``hdf5`` Anaconda package (but not the above ``hdf5-parallel`` package).

Compilation
===========

Compilation of RH 1.5D consists of two steps:

1. Compilation of the geometry-independent main libraries (``librh.a`` and ``librh_f90.a``)
2. Compilation of the ``rh15d_mpi`` tree and main binaries

RH 1.5D has been compiled in a variety of architectures and compilers, including gcc, the Intel compilers, and clang. As for MPI implementations, it has been tested with SGI's mpt, OpenMPI, mpich, mvapich, and Intel's MPI.

Main libraries
--------------

First, one needs to set the environment variables ``OS`` and ``CPU``:

.. code-block:: bash

   export CPU=`uname -m`
   export OS=`uname -s`

.. note::
   All the shell commands given in this manual are for bash, so you'll have to modify them if using another shell.

The main Makefile will then look for an architecture-dependent Makefile in ``rh/makefile.$CPU.$OS``. If a Makefile for your system combination does not exist, you'll have to create a new Makefile and adapt it to your configuration. You need to make sure that the architecture-dependent Makefile reflects your system's configuration (i.e., compiler names and flags).

After setting the correct compiler, just build the main libraries with ``make`` on the ``rh`` directory. If successful, the compilation will produce the two library files ``librh.a`` and ``librh_f90.a``.

Program binaries
----------------

Go to the ``rh/rh15d_mpi/`` directory and update the Makefile with your compiler and flags. You will need to set ``CC`` to the MPI alias (e.g. ``mpicc``). The path to the HDF5 library needs to be explicitly set in ``HDF5_DIR``. In Fram and Hexagon this is already stored in the ``HDF5_DIR`` environment variable.

If you are using HDF5 parallel from Anaconda, you need to set ``HDF5_DIR`` to your Anaconda directory plus ``include/`` (e.g. ``~/anaconda/include``).

If your version of HDF5 was not built as a shared binary, you need to link HDF5 and other used libraries directly. Set the ``LDFLAGS`` accordingly, and update the ``LIBS`` variable to contain all the other libraries. For Pleiades, make sure your Makefile contains the following:

.. code-block:: bash

    OTHER_LIBRARY_DIR = /path/to/library
    HDF5_DIR = /path/to/hdf5
    LDFLAGS = -L../ -L$(OTHER_LIBRARY_DIR)/lib/  -L$(HDF5_DIR)/lib/
    LIBS = -lrh -lrh_f90 $(ARCHLIBS) -lhdf5_hl -lhdf5 -lz -lm

Once the Makefile is updated, compilation is achieved with ``make``. The following executables will be created:

============== =======================================================================
File           Description
============== =======================================================================
rh15d_ray_pool Main RH 1.5D binary, uses a job pool (see :ref:`binaries-label`)
rh15d_ray      Alternative RH 1.5D binary. **Deprecated.** This program runs much slower
               than rh15d_ray_pool and is kept for backwards compatibility only. Will
               be removed in a future revision.
rh15d_lteray   Special binary for running in LTE
============== =======================================================================

Run directory
=============

Once compiled, you can copy or link the binaries to a run directory. This directory will contain all the necessary input files, and it should contain two subdirectories called ``output`` and ``scratch``.

.. warning::
   If the subdirectories ``output`` and ``scratch`` do not exist in the directory where the code is run, the code will crash with an obscure error message.

The run directory can be located anywhere, but it **must** have a directory called ``Atoms`` two levels below (i.e. ``../../Atoms/``) with the ``Barklem_*data.dat`` files. This is because these relative paths are hardcoded in ``barklem.c``. The input files in the run directory must obviously point to existing path names.
